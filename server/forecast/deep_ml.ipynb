{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from forecast.games_dataset_features import *\n",
    "from forecast.ml.module import ModuleExt\n",
    "\n",
    "\n",
    "Dataset = namedtuple('Dataset', ['train_x', 'train_y', 'test_x', 'test_y'])\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6615, 107)\n(6615,)\n(6615,)\n"
     ]
    }
   ],
   "source": [
    "dataset_file = 'games_10_3'\n",
    "x_origin = np.load('./server/forecast/dataset/{}_x.npy'.format(dataset_file))\n",
    "y = np.load('./server/forecast/dataset/{}_y.npy'.format(dataset_file))\n",
    "\n",
    "print(x_origin.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# y2 is a target for win/lose only\n",
    "y2 = y.copy()\n",
    "y2[y2 == 1] = 0\n",
    "y2[y2 == 2] = 1\n",
    "y2[y2 == 3] = 1\n",
    "print(y2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def prepare_dataset(features, target, test_data_percentage=0.2, scaler=None, transform_func=None):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=test_data_percentage)\n",
    "    if scaler is not None:\n",
    "        scaler.fit(x_train)  \n",
    "        x_train = scaler.transform(x_train)  \n",
    "        x_test = scaler.transform(x_test)\n",
    "    if transform_func is not None:\n",
    "        x_train = transform_func(x_train)\n",
    "        x_test = transform_func(x_test)\n",
    "    return Dataset(\n",
    "        torch.from_numpy(x_train).float(),\n",
    "        torch.from_numpy(y_train).long(),\n",
    "        torch.from_numpy(x_test).float(),\n",
    "        torch.from_numpy(y_test).long()\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    predictions = model.predict(data.test_x)\n",
    "    print(\"Train Accuracy: \", accuracy_score(data.train_y, model.predict(data.train_x)))\n",
    "    print(\"Test Accuracy: \", accuracy_score(data.test_y, predictions))\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(data.test_y, predictions))\n",
    "\n",
    "\n",
    "def transform_game_to_conv1(data):\n",
    "    return data[:, FEATURES_STATS_ONLY].reshape((data.shape[0], 6, FEATURE_STAT_COUNT))\n",
    "\n",
    "\n",
    "def get_model_output(model, input_size):\n",
    "    def conv_output(in_size, kernel, stride, padding, dilation):\n",
    "        return int(floor(((in_size + 2*padding - dilation*(kernel - 1) - 1) / stride) + 1))\n",
    "\n",
    "    out_channels = 0\n",
    "    d0, d1 = 0, 0\n",
    "    if len(input_size) == 1:\n",
    "        d0, = input_size\n",
    "    elif len(input_size) == 2:\n",
    "        d0, d1 = input_size\n",
    "\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Sequential) or isinstance(m, nn.ModuleList):\n",
    "            continue\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            d0 = conv_output(d0, m.kernel_size[0], m.stride[0], m.padding[0], m.dilation[0])\n",
    "            out_channels = m.out_channels\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            d0 = conv_output(d0, m.kernel_size[0], m.stride[0], m.padding[0], m.dilation[0])\n",
    "            d1 = conv_output(d1, m.kernel_size[1], m.stride[1], m.padding[1], m.dilation[1])\n",
    "            out_channels = m.out_channels\n",
    "        elif isinstance(m, nn.MaxPool1d):\n",
    "            d0 = conv_output(d0, m.kernel_size, m.stride, m.padding, m.dilation)\n",
    "        elif isinstance(m, nn.MaxPool2d):\n",
    "            d0 = conv_output(d0, m.kernel_size, m.stride, m.padding, m.dilation)\n",
    "            d1 = conv_output(d1, m.kernel_size, m.stride, m.padding, m.dilation)\n",
    "    return (out_channels, d0, d1)[:len(input_size) + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nFitting for each of 15 candidates\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.001, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5311320754716982, time: 134.4786570072174\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 1e-05, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5274102079395085, time: 248.69393348693848\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5444234404536862, time: 148.38032937049866\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5434782608695652, time: 173.80008268356323\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.001, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5132325141776938, time: 70.00593709945679\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5103773584905661, time: 190.1349561214447\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 1e-05, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5245746691871456, time: 189.73961114883423\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.505671077504726, time: 192.38954377174377\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.001, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5453686200378072, time: 119.51050019264221\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5311909262759924, time: 238.72623419761658\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.4981132075471698, time: 63.87706518173218\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.001, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5113421550094518, time: 101.20760178565979\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 1e-05, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5500945179584121, time: 88.29166293144226\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.sgd.SGD'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5415879017013232, time: 134.341078042984\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 1e-05, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5179584120982986, time: 192.78613901138306\n\n\n\n{'opt_lr': 1e-05, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_features': 107, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_hidden_size': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], 'mod_dropout': 0.5, 'fit_epochs': 90, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\n0.5500945179584121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6781934996220711\nTest Accuracy:  0.5185185185185185\nConfusion matrix\n [[482 204]\n [433 204]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
    "\n",
    "from forecast.ml.hparam_tuning import RandomSearchCV\n",
    "\n",
    "\n",
    "class GameModelFC(ModuleExt):\n",
    "    def __init__(self, num_classes=2, num_features=10, hidden_size=None, dropout=None):\n",
    "        super(GameModelFC, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_size[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[2], hidden_size[3]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[3], hidden_size[4]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[4], hidden_size[5]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[5], hidden_size[6]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[6], hidden_size[7]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[7], hidden_size[8]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[8], hidden_size[9]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size[9], hidden_size[10]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size[10], num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset = prepare_dataset(x_origin, y2, scaler=scaler)\n",
    "\n",
    "params = {\n",
    "    'mod_num_classes': [2],\n",
    "    'mod_num_features': [FEATURE_COUNT],\n",
    "    'mod_hidden_size': [\n",
    "        [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
    "        [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 100],\n",
    "        [100, 200, 200, 200, 300, 300, 200, 200, 200, 100, 50]\n",
    "    ],\n",
    "    'mod_dropout': [0.5],\n",
    "    'mod_init_weights': ['he'],\n",
    "    'fit_epochs': [90],\n",
    "    'opt_cls': [Adam, SGD, RMSprop],\n",
    "    'opt_lr': [1e-03, 1e-04, 1e-05],\n",
    "    'ann_cls': [StepLR],\n",
    "    'ann_step_size': [30]\n",
    "}\n",
    "\n",
    "rscv = RandomSearchCV(GameModelFC, params, try_count=15, cv=5, verbose=1)\n",
    "rscv.fit(dataset.train_x, dataset.train_y)\n",
    "print('\\n\\n')\n",
    "print(rscv.best_params)\n",
    "print(rscv.best_score)\n",
    "\n",
    "evaluate_model(rscv.best_model, dataset)\n",
    "net = rscv.best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvLayer = namedtuple('ConvLayer', ['c_in', 'c_out', 'c_kern', 'c_pad', 'mp_kern'])\n",
    "\n",
    "\n",
    "class GameModel(ModuleExt):\n",
    "    def __init__(self, num_classes=2, conv_layer_params=None, classifier_params=None):\n",
    "        super(GameModel, self).__init__()\n",
    "        hidden_size, dropout = classifier_params\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(conv_layer_params[0].c_in, conv_layer_params[0].c_out,\n",
    "                      kernel_size=conv_layer_params[0].c_kern, padding=conv_layer_params[0].c_pad),\n",
    "            nn.BatchNorm1d(conv_layer_params[0].c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=conv_layer_params[0].mp_kern),\n",
    "\n",
    "            nn.Conv1d(conv_layer_params[1].c_in, conv_layer_params[1].c_out,\n",
    "                      kernel_size=conv_layer_params[1].c_kern, padding=conv_layer_params[1].c_pad),\n",
    "            nn.BatchNorm1d(conv_layer_params[1].c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool1d(kernel_size=conv_layer_params[1].mp_kern),\n",
    "\n",
    "            nn.Conv1d(conv_layer_params[2].c_in, conv_layer_params[2].c_out,\n",
    "                      kernel_size=conv_layer_params[1].c_kern, padding=conv_layer_params[2].c_pad),\n",
    "            nn.BatchNorm1d(conv_layer_params[2].c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool1d(kernel_size=conv_layer_params[2].mp_kern),\n",
    "\n",
    "            nn.Conv1d(conv_layer_params[3].c_in, conv_layer_params[3].c_out,\n",
    "                      kernel_size=conv_layer_params[3].c_kern, padding=conv_layer_params[3].c_pad),\n",
    "            nn.BatchNorm1d(conv_layer_params[3].c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=conv_layer_params[3].mp_kern),\n",
    "        )\n",
    "        l1_output = get_model_output(self.features, (FEATURE_STAT_COUNT,))\n",
    "        flat_out = functools.reduce(lambda x, y: x*y, l1_output, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Dropout(p=dropout),\n",
    "            nn.Linear(flat_out, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nFitting for each of 8 candidates\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=2, c_pad=1, mp_kern=2)], 'mod_classifier_params': (100, 0.5), 'fit_epochs': 80, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5118035882908404, time: 230.2893660068512\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=2, c_pad=1, mp_kern=2)], 'mod_classifier_params': (120, 0.5), 'fit_epochs': 80, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5136921624173749, time: 204.582772731781\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=80, c_out=100, c_kern=1, c_pad=0, mp_kern=2)], 'mod_classifier_params': (100, 0.5), 'fit_epochs': 120, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5179584120982986, time: 273.0029032230377\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=2, c_pad=1, mp_kern=2)], 'mod_classifier_params': (100, 0.5), 'fit_epochs': 120, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.500945179584121, time: 310.53158950805664\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.rmsprop.RMSprop'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=50, c_kern=2, c_pad=1, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=2, c_pad=1, mp_kern=2)], 'mod_classifier_params': (120, 0.5), 'fit_epochs': 120, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5359168241965974, time: 309.2411103248596\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=80, c_out=100, c_kern=1, c_pad=0, mp_kern=2)], 'mod_classifier_params': (120, 0.5), 'fit_epochs': 80, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5231350330500472, time: 187.00966000556946\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=80, c_out=100, c_kern=1, c_pad=0, mp_kern=2)], 'mod_classifier_params': (100, 0.5), 'fit_epochs': 120, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5316336166194523, time: 306.3104827404022\n\n============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=80, c_out=100, c_kern=1, c_pad=0, mp_kern=2)], 'mod_classifier_params': (100, 0.5), 'fit_epochs': 80, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\nResult: score: 0.5378071833648393, time: 212.24958062171936\n\n\n\n{'opt_lr': 0.0001, 'opt_cls': <class 'torch.optim.adam.Adam'>, 'mod_num_classes': 2, 'mod_init_weights': 'he', 'mod_conv_layer_params': [ConvLayer(c_in=6, c_out=20, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=20, c_out=50, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=50, c_out=80, c_kern=1, c_pad=0, mp_kern=2), ConvLayer(c_in=80, c_out=100, c_kern=1, c_pad=0, mp_kern=2)], 'mod_classifier_params': (100, 0.5), 'fit_epochs': 80, 'ann_step_size': 30, 'ann_cls': <class 'torch.optim.lr_scheduler.StepLR'>}\n0.5378071833648393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8252078609221466\nTest Accuracy:  0.5011337868480725\nConfusion matrix\n [[416 301]\n [359 247]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
    "\n",
    "from forecast.ml.hparam_tuning import RandomSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset = prepare_dataset(x_origin, y2, scaler=scaler, transform_func=transform_game_to_conv1)\n",
    "\n",
    "params = {\n",
    "    'mod_num_classes': [2],\n",
    "    'mod_conv_layer_params': [\n",
    "        [ConvLayer(6, 20, 1, 0, 2), ConvLayer(20, 50, 1, 0, 2), ConvLayer(50, 80, 1, 0, 2), ConvLayer(80, 100, 1, 0, 2)],\n",
    "        [ConvLayer(6, 20, 2, 1, 2), ConvLayer(20, 50, 2, 1, 2), ConvLayer(50, 50, 2, 1, 2), ConvLayer(50, 80, 2, 1, 2)]\n",
    "    ],\n",
    "    'mod_classifier_params': [(100, 0.5), (120, 0.5)],\n",
    "    'mod_init_weights': ['he'],\n",
    "    'fit_epochs': [80, 120],\n",
    "    'opt_cls': [Adam, RMSprop],\n",
    "    'opt_lr': [0.0001],\n",
    "    'ann_cls': [StepLR],\n",
    "    'ann_step_size': [30]\n",
    "}\n",
    "\n",
    "rscv = RandomSearchCV(GameModel, params, try_count=8, cv=5, verbose=1)\n",
    "rscv.fit(dataset.train_x, dataset.train_y)\n",
    "print('\\n\\n')\n",
    "print(rscv.best_params)\n",
    "print(rscv.best_score)\n",
    "\n",
    "evaluate_model(rscv.best_model, dataset)\n",
    "net = rscv.best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
    "\n",
    "from forecast.ml.hparam_tuning import RandomSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset = prepare_dataset(x_origin, y2, scaler=scaler, transform_func=transform_game_to_conv1)\n",
    "\n",
    "net = GameModel(conv_layer_params=(6, 1, 0, 1), classifier_params=(12, 0.5))\n",
    "net.init_weights(mode='he')\n",
    "\n",
    "optimizer = Adam(net.parameters(), lr=0.0001)\n",
    "annealing = StepLR(optimizer, step_size=30)\n",
    "\n",
    "net.fit(dataset.train_x, dataset.train_y, optimizer, annealing=annealing, epochs=80, validation_split=0.3)\n",
    "\n",
    "evaluate_model(net, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = range(0, net.history.shape[0])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.set_ylim(0, 1.5)\n",
    "ax1.plot(x_axis, net.history[:, ModuleExt.HISTORY_TRAIN_LOSS], 'ro-', label='Train loss')\n",
    "ax1.plot(x_axis, net.history[:, ModuleExt.HISTORY_VAL_LOSS], 'bo-', label='Validation loss')\n",
    "ax1.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.plot(x_axis, net.history[:, ModuleExt.HISTORY_TRAIN_ACC], 'ro-', label='Train acc')\n",
    "ax2.plot(x_axis, net.history[:, ModuleExt.HISTORY_VAL_ACC], 'bo-', label='Validation acc')\n",
    "ax2.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
